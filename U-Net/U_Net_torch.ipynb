{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y63bMbis4O54"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`num_classes` (int): number of classes to segment\n",
        "\n",
        "`in_features` (int): number of input features in the first convolution\n",
        "\n",
        "`drop_rate` (float): dropout rate of the last two encoders\n",
        "\n",
        "`filter` (list of 5 ints): number of output features at each level"
      ],
      "metadata": {
        "id": "3MxjGPVFU5Au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet(nn.Module):\n",
        "  def __init__(self,num_classes,in_features=1,drop_rate=0.5,filters=(64,128,256,512,1024)):\n",
        "    super(Unet,self).__init__()\n",
        "\n",
        "    self.encoder1= Encoder(in_features, filters[0])\n",
        "    self.encoder2= Encoder(filters[0], filters[1])\n",
        "    self.encoder3= Encoder(filters[1], filters[2])\n",
        "    self.encoder4= Encoder(filters[2], filters[3], drop_rate)\n",
        "    self.encoder5= Encoder(filters[3], filters[4], drop_rate)\n",
        "\n",
        "    self.decoder1= Decoder(filters[4], filters[3])\n",
        "    self.decoder2= Decoder(filters[3],filters[2])\n",
        "    self.decoder3= Decoder(filters[2], filters[1])\n",
        "    self.decoder4= Decoder(filters[1],filters[0])\n",
        "\n",
        "    # final classifier\n",
        "\n",
        "    self.classifier= nn.Conv2d(filters[0], num_classes,1)\n",
        "\n",
        "    for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_normal(m.weight)\n",
        "\n",
        "  def forward(self,x):\n",
        "    encoder_1= self.encoder1(x)\n",
        "    encoder_2= self.encoder2(F.max_pool2d(encoder_1,2))\n",
        "    encoder_3= self.encoder3(F.max_pool2d(encoder_2,2))\n",
        "    encoder_4= self.encoder4(F.max_pool2d(encoder_3,2))\n",
        "    encoder_5= self.encoder5(F.max_pool2d(encoder_4,2))\n",
        "\n",
        "    f_decoder= self.decoder1(encoder_5,encoder_4)\n",
        "    f_decoder= self.decoder2(f_decoder,encoder_3)\n",
        "    f_decoder= self.decoder3(f_decoder,encoder_2)\n",
        "    f_decoder= self.decoder4(f_decoder,encoder_1)\n",
        "\n",
        "    return self.calssifier(f_decoder)\n",
        "\n"
      ],
      "metadata": {
        "id": "x07wPgXM5Fii"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder layer encodes the features along the contracting path (left side),drop_rate parameter is used with respect to the paper\n",
        "\n",
        "`e_in_feature` (int): number of input features\n",
        "\n",
        "`e_out_feature` (int): number of output features\n",
        "\n",
        "`drop_rate` (float): dropout rate at the end of the block\n"
      ],
      "metadata": {
        "id": "PUqaTwZwVieg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,e_in_feature,e_out_feature,drop_rate=0):\n",
        "    super(Encoder,self).__init__()\n",
        "\n",
        "    layers=[nn.Conv2d(e_in_feature,e_out_feature,3),\n",
        "            nn.Relu(inplace=True),\n",
        "            nn.Conv2d(e_out_feature,e_out_feature,3),\n",
        "            nn.Relu(inplace=True)]\n",
        "\n",
        "    if drop_rate>0:\n",
        "      layers += [nn.Dropout(drop_rate)]\n",
        "\n",
        "    self.features= nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.features(x)"
      ],
      "metadata": {
        "id": "B04kSTbxOY9V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder layer decodes the features by performing deconvolutions and concatenating the resulting features with cropped features from the corresponding encoder (skip-connections).\n",
        "\n",
        "`d_in_feature` (int): number of input features\n",
        "\n",
        "`d_out_feature` (int): number of output features"
      ],
      "metadata": {
        "id": "nmfnD-tnWBut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,d_in_feature,d_out_feature):\n",
        "    super(Decoder,self).__init__()\n",
        "\n",
        "    self.encoderr= Encoder(d_in_feature,d_out_feature)\n",
        "    self.decoderr= nn.ConvTranspose2d(d_in_feature,d_out_feature,2,2)\n",
        "\n",
        "  def forward(self,x,f_encoder):\n",
        "    f_decoder= F.relu(self.decoderr(x),True)\n",
        "\n",
        "    crop_size = f_decoder.size(-1)\n",
        "    offset = (f_encoder.size(-1) - crop_size) // 2\n",
        "    crop = f_encoder[:, :, offset:offset + crop_size,\n",
        "                            offset:offset + crop_size]\n",
        "    return self.encoder(torch.cat([f_decoder, crop], 1))"
      ],
      "metadata": {
        "id": "19cufxiqOXyb"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}