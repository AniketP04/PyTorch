{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRboz4A+etiQVTII4lFTd7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AniketP04/PyTorch/blob/main/Neural_networks_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JQPBfXlP5TVl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First up, we need to get our dataset. This is provided through the torchvision package. The code below will download the MNIST dataset, then create training and test datasets for us."
      ],
      "metadata": {
        "id": "yVVGwAUj8qg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "egw6TRKs7uvJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the training data loaded into `train_loader` and we make that an iterator with `iter(trainloader)`.\n",
        "\n",
        "`images` is just a tensor with size `(64, 1, 28, 28)`. So, 64 images per batch, 1 color channel, and 28x28 images."
      ],
      "metadata": {
        "id": "KOg3Io8X8_t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    print(type(images))\n",
        "    print(images.shape)\n",
        "    print(labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7jM2CBa8Td2",
        "outputId": "cb7467a2-8e55-4a6b-f015-449b1ef370ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "TcWID-zP9XSs",
        "outputId": "3eb70b90-2de5-4cc2-a20a-ba32da78d2f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sigmoid activation function** as we need 10 output units, one for each digit."
      ],
      "metadata": {
        "id": "9QOXgmVzHAtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def activation(x):\n",
        "    return 1/(1+torch.exp(-x))\n",
        "\n",
        "\n",
        "inputs = images.view(images.shape[0], -1)\n",
        "\n",
        "w1 = torch.randn(784, 256)\n",
        "b1 = torch.randn(256)\n",
        "\n",
        "w2 = torch.randn(256, 10)\n",
        "b2 = torch.randn(10)\n",
        "\n",
        "h = activation(torch.mm(inputs, w1) + b1)\n",
        "\n",
        "out = torch.mm(h, w2) + b2"
      ],
      "metadata": {
        "id": "l_6WR9Af-iH_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)\n",
        "\n",
        "probabilities = softmax(out)\n",
        "\n",
        "print(probabilities.shape)\n",
        "print(probabilities.sum(dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MR1eL9tGzaj",
        "outputId": "4172ce3f-79e8-40d8-b1aa-0d2e57fa64f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building networks with PyTorch**"
      ],
      "metadata": {
        "id": "WwhQtMbYIAl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "ztggr0KtICBN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.hidden = nn.Linear(784,256)\n",
        "        self.hidden1 = nn.Linear(256,64)\n",
        "        self.output = nn.Linear(64,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden(x))\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = Network()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KyJqzOEIHOM",
        "outputId": "2a4dcb8d-279f-4f59-9187-662134993042"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network(\n",
            "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (hidden1): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "class Network(nn.Module):\n",
        "```\n",
        "\n",
        "Here we're inheriting from `nn.Module`. Combined with `super().__init__()` this creates a class that tracks the architecture and provides a lot of useful methods and attributes. It is mandatory to inherit from `nn.Module` when you're creating a class for your network. The name of the class itself can be anything.\n",
        "\n",
        "```python\n",
        "self.hidden = nn.Linear(784, 256)\n",
        "```\n",
        "\n",
        "This line creates a module for a linear transformation, $x\\mathbf{W} + b$, with 784 inputs and 256 outputs and assigns it to `self.hidden`. The module automatically creates the weight and bias tensors which we'll use in the `forward` method. You can access the weight and bias tensors once the network (`net`) is created with `net.hidden.weight` and `net.hidden.bias`.\n",
        "\n",
        "```python\n",
        "self.output = nn.Linear(256, 10)\n",
        "```\n",
        "\n",
        "Similarly, this creates another linear transformation with 256 inputs and 10 outputs.\n",
        "\n",
        "```python\n",
        "self.sigmoid = nn.Sigmoid()\n",
        "self.softmax = nn.Softmax(dim=1)\n",
        "```\n",
        "\n",
        "Here I defined operations for the sigmoid activation and softmax output. Setting `dim=1` in `nn.Softmax(dim=1)` calculates softmax across the columns.\n",
        "\n",
        "```python\n",
        "def forward(self, x):\n",
        "```\n",
        "\n",
        "PyTorch networks created with `nn.Module` must have a `forward` method defined. It takes in a tensor `x` and passes it through the operations you defined in the `__init__` method.\n",
        "\n",
        "```python\n",
        "x = self.hidden(x)\n",
        "x = self.sigmoid(x)\n",
        "x = self.output(x)\n",
        "x = self.softmax(x)\n",
        "```\n",
        "\n",
        "Here the input tensor `x` is passed through each operation a reassigned to `x`. We can see that the input tensor goes through the hidden layer, then a sigmoid function, then the output layer, and finally the softmax function.\n"
      ],
      "metadata": {
        "id": "ZgYPtEedNalY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using `nn.Sequential`**"
      ],
      "metadata": {
        "id": "tPgjzkp1TTv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.Softmax(dim=1))\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFRRG-JnTUGr",
        "outputId": "b8178e2c-4a79-4c7d-e9a9-9b40d6450989"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "model = nn.Sequential(OrderedDict([\n",
        "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
        "                      ('relu1', nn.ReLU()),\n",
        "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
        "                      ('relu2', nn.ReLU()),\n",
        "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
        "                      ('softmax', nn.Softmax(dim=1))]))\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmHnmbD3Tz4d",
        "outputId": "c45c8af5-9726-40d6-e178-72f3ea934bc0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}